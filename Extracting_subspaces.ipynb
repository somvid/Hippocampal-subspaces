{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29f63235",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04703d19-5a52-4957-a81d-7ebf3ac0d027",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from ipywidgets import *\n",
    "from scipy.stats import zscore, pearsonr, kendalltau, spearmanr, ttest_rel, ttest_1samp, ttest_ind\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pickle\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "mpl.rcParams['axes.linewidth'] = 2\n",
    "mpl.rcParams['xtick.major.width'] = 2\n",
    "mpl.rcParams['ytick.major.width'] = 2\n",
    "mpl.rcParams['xtick.major.size'] = 5\n",
    "mpl.rcParams['ytick.major.size'] = 5\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.bottom'] = False\n",
    "mpl.rcParams['axes.spines.left'] = True\n",
    "\n",
    "def cos_sim(A, B):\n",
    "    return np.dot(A, B)/(np.linalg.norm(A)*np.linalg.norm(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aa45ed3-95ac-40a6-9bdf-f5ed21d5221a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "986 + 914 + 666 = 2566\n"
     ]
    }
   ],
   "source": [
    "exclude_short_movie = np.load('/home/dasom/State_dynamics/results/exclude_short_movie.npy')\n",
    "\n",
    "rest_tr_ep1 = np.load('/home/dasom/State_dynamics/results/rest_tr_ep1.npy')\n",
    "rest_tr_ep2 = np.load('/home/dasom/State_dynamics/results/rest_tr_ep2.npy')\n",
    "rest_tr_ep3 = np.load('/home/dasom/State_dynamics/results/rest_tr_ep3.npy')\n",
    "\n",
    "rest_total = rest_tr_ep1.shape[0] + rest_tr_ep2.shape[0] + rest_tr_ep3.shape[0]\n",
    "rest_tr = np.hstack([rest_tr_ep1, rest_tr_ep2+996, rest_tr_ep3+996+958])\n",
    "print(f'{rest_tr_ep1.shape[0]} + {rest_tr_ep2.shape[0]} + {rest_tr_ep3.shape[0]} = {rest_total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fcd909-0791-4ae5-a126-841ac4aeea74",
   "metadata": {},
   "source": [
    "## Novelty and Memorability measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9d5848",
   "metadata": {},
   "source": [
    "#### Memorability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f158432",
   "metadata": {},
   "outputs": [],
   "source": [
    "Memorability_score_total = np.load('/home/dasom/State_dynamics/results/Memorability_score_total.npy')\n",
    "Memorability_score = np.load('/home/dasom/State_dynamics/results/Memorability_score.npy')\n",
    "Memorability_score_binary = np.load('/home/dasom/State_dynamics/results/Memorability_score_binary.npy')\n",
    "memorability = np.mean(Memorability_score, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648b9f22",
   "metadata": {},
   "source": [
    "#### Novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6152275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cooccur_sim = np.load('/home/dasom/State_dynamics/results/cooccur_similarity.npy')\n",
    "\n",
    "nove_cooccur_1 = np.where(cooccur_sim >= np.percentile(cooccur_sim,200/3))[0]\n",
    "nove_cooccur_2 = np.where((cooccur_sim >= np.percentile(cooccur_sim,100/3)) & (cooccur_sim < np.percentile(cooccur_sim,200/3)))[0]\n",
    "nove_cooccur_3 = np.where(cooccur_sim < np.percentile(cooccur_sim,100/3))[0]\n",
    "\n",
    "valence_sim = np.load('/home/dasom/State_dynamics/results/valence_similarity.npy')\n",
    "\n",
    "nove_valence_1 = np.where(valence_sim >= np.percentile(valence_sim,200/3))[0]\n",
    "nove_valence_2 = np.where((valence_sim >= np.percentile(valence_sim,100/3)) & (valence_sim < np.percentile(valence_sim,200/3)))[0]\n",
    "nove_valence_3 = np.where(valence_sim < np.percentile(valence_sim,100/3))[0]\n",
    "\n",
    "### Just valence\n",
    "valence = np.load('/home/dasom/State_dynamics/results/valence_just.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relationship novelty and memorability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2023)\n",
    "fig = plt.figure(figsize = [10,5])\n",
    "axs = fig.add_subplot(1,2,1)\n",
    "subj_memory = np.array([np.mean(Memorability_score[:,i], axis=1) for i in [nove_cooccur_1, nove_cooccur_2, nove_cooccur_3]])\n",
    "violin_parts = axs.violinplot(subj_memory.T, np.arange(3), showmeans=False, showmedians=False, showextrema=False, widths = 0.5)\n",
    "for vp in violin_parts['bodies']:\n",
    "    vp.set_facecolor('#FF0000')  # aa0000 FF00FF 00FFFF\n",
    "    vp.set_edgecolor('#000000')\n",
    "    vp.set_alpha(0.5)\n",
    "\n",
    "for c in range(3):\n",
    "    plt.scatter(np.random.normal(loc = c, scale = 0.02, size = 24), subj_memory[c], color = 'grey')\n",
    "    plt.hlines(np.mean(subj_memory[c]), c-0.1, c+0.1, zorder = 1, color = 'k')\n",
    "\n",
    "axs.set_xticks([0,1,2])\n",
    "axs.set_yticks([0,0.1,0.2,0.3,0.4,0.5])\n",
    "axs.set_yticklabels([0,0.1,0.2,0.3,0.4,0.5])\n",
    "axs.set_xlim([-0.5,2.5])\n",
    "axs.set_ylim([0, 0.5])\n",
    "\n",
    "axs = fig.add_subplot(1,2,2)\n",
    "subj_memory = np.array([np.mean(Memorability_score[:,i], axis=1) for i in [nove_valence_1, nove_valence_2, nove_valence_3]])\n",
    "violin_parts = axs.violinplot(subj_memory.T, np.arange(3), showmeans=False, showmedians=False, showextrema=False, widths = 0.5)\n",
    "for vp in violin_parts['bodies']:\n",
    "    vp.set_facecolor('#9C27B0')  # aa0000 FF00FF 00FFFF\n",
    "    vp.set_edgecolor('#000000')\n",
    "    vp.set_alpha(0.5)\n",
    "\n",
    "for c in range(3):\n",
    "    plt.scatter(np.random.normal(loc = c, scale = 0.02, size = 24), subj_memory[c], color = 'grey')\n",
    "    plt.hlines(np.mean(subj_memory[c]), c-0.1, c+0.1, zorder = 1, color = 'k')\n",
    "\n",
    "axs.set_xticks([0,1,2])\n",
    "axs.set_yticks([0,0.1,0.2,0.3,0.4,0.5])\n",
    "axs.set_yticklabels([0,0.1,0.2,0.3,0.4,0.5])\n",
    "axs.set_xlim([-0.5,2.5])\n",
    "axs.set_ylim([0, 0.5])\n",
    "fig.tight_layout()\n",
    "fig.savefig('/home/dasom/Dropbox/ubuntu-window/미팅자료/Neural_dynamics/Memory_novelty_cooccur_valence/Relationship_btw_novelty_memory.png', dpi=300, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_mean = np.array([np.mean(Memorability_score[:,i], axis=1) for i in [nove_cooccur_1, nove_cooccur_2, nove_cooccur_3]])\n",
    "score_mean = np.array([np.mean(Memorability_score[:,i], axis=1) for i in [nove_valence_1, nove_valence_2, nove_valence_3]])\n",
    "ttest_rel(score_mean[0], score_mean[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movie event onset and offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_start = np.load('/home/dasom/State_dynamics/results/movie_event_start_idx.npy')\n",
    "overlap_end = np.load('/home/dasom/State_dynamics/results/movie_event_boundary_idx.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall onset and offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_start_tot = np.load('/home/dasom/State_dynamics/results/Recall_event_onset.npy', allow_pickle=True)\n",
    "event_end_tot = np.load('/home/dasom/State_dynamics/results/Recall_event_offset.npy', allow_pickle=True)\n",
    "event_idx = np.load('/home/dasom/State_dynamics/results/Recall_event_idx.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df5ec23-0904-4b5f-884c-ac8f840161e0",
   "metadata": {},
   "source": [
    "## Brain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab16d14d-04ff-4613-80a4-b4ff806294b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/media/dasom/caee0336-77a9-438c-af2f-7cf5b88293e7/dasom/SM_DATA/social_movie1/results/fMRI_data/movie_data_ex2_sc_sm.pickle', 'rb') as f:\n",
    "    movie_data = pickle.load(f)\n",
    "    \n",
    "# with open('/media/dasom/caee0336-77a9-438c-af2f-7cf5b88293e7/dasom/SM_DATA/social_movie1/results/fMRI_data/recall_data_ex2_sc_sm.pickle', 'rb') as f:\n",
    "#     recall_data_concat = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecf154a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_mask = nib.load(f'/home/dasom/SM_DATA/mri_data/mask_files/MNI152NLin2009cAsym_3mm_mask.nii.gz').get_fdata()\n",
    "mask = nib.load('/home/dasom/SM_DATA/mri_data/mask_files/BNA_3mm_atlas.nii.gz').get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a40195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie viewing\n",
    "\n",
    "window_length = 21\n",
    "\n",
    "roi_mask1 = np.hstack([np.where(mask[brain_mask > 0] == r)[0] for r in [215,216,217,218]]) # HIPP\n",
    "roi_mask2 = np.hstack([np.where(mask[brain_mask > 0] == r)[0] for r in [111,112,119,120]]) # PHC\n",
    "roi_mask3 = np.hstack([np.where(mask[brain_mask > 0] == r)[0] for r in [115,116]]) # EC\n",
    "roi_mask4 = np.hstack([np.where(mask[brain_mask > 0] == r)[0] for r in [117,118]]) # PRC\n",
    "roi_mask5 = np.hstack([np.where(mask[brain_mask > 0] == r)[0] for r in [75,76,79,80]]) # STG\n",
    "roi_mask6 = np.hstack([np.where(mask[brain_mask > 0] == r)[0] for r in [87,88,121,122]]) # STS\n",
    "roi_mask7 = np.hstack([np.where(mask[brain_mask > 0] == r)[0] for r in [143,144]]) # TPJ\n",
    "roi_mask8 = np.hstack([np.where(mask[brain_mask > 0] == r)[0] for r in [153,154,175,176]]) # PMC\n",
    "roi_mask9 = np.hstack([np.where(mask[brain_mask > 0] == r)[0] for r in [13,14]]) # DMPFC\n",
    "roi_mask10 = np.hstack([np.where(mask[brain_mask > 0] == r)[0] for r in [41,42]]) # VMPFC\n",
    "roi_mask11 = np.hstack([np.where(mask[brain_mask > 0] == r)[0] for r in [189,190,191,192,193,194]]) # VC\n",
    "roi_mask12 = np.hstack([np.where(mask[brain_mask > 0] == r)[0] for r in [71,72]]) # AC\n",
    "roi_mask13 = np.hstack([np.where(mask[brain_mask > 0] == r)[0] for r in [179,187,188]]) # ACC\n",
    "\n",
    "patterns = []\n",
    "# for rm in [roi_mask1,roi_mask2,roi_mask3,roi_mask4,roi_mask5,roi_mask6,roi_mask7,roi_mask8,roi_mask9,roi_mask10,roi_mask11,roi_mask12,roi_mask13]:\n",
    "for rm in [roi_mask1]:\n",
    "    pattern = []\n",
    "    for s in range(movie_data.shape[0]):\n",
    "        movie_data_sub = movie_data[s, rm]\n",
    "        ev_pattern = []\n",
    "        for ev in overlap_end[exclude_short_movie[1:]]:\n",
    "            ev_pattern.append(movie_data_sub[:,ev-6:ev+15])\n",
    "        pattern.append(ev_pattern)\n",
    "    # patterns.append(np.array(pattern))\n",
    "    patterns.append(gaussian_filter1d(pattern, sigma = 2, axis=-1)) # For visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "2c8bbb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# narrative recall\n",
    "window_length = 21 # 18 for end\n",
    "roi_mask1 = np.hstack([np.where(mask[brain_mask > 0] == r)[0] for r in [215,216,217,218]]) # HIPP\n",
    "\n",
    "patterns_recall = []\n",
    "for rm in [roi_mask1]:\n",
    "    pattern = []\n",
    "    for s in range(len(recall_data_concat)):\n",
    "        recall_data_sub = recall_data_concat[s][rm]\n",
    "        ev_pattern = []\n",
    "        for ev in event_start_tot[s]:\n",
    "            ev_pattern.append(recall_data_sub[:,ev-6:ev+15])\n",
    "        pattern.append(np.array(ev_pattern))\n",
    "    patterns_recall.append(pattern)\n",
    "    # patterns.append(gaussian_filter1d(pattern, sigma = 2, axis=-1)) # For visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736b2dc6",
   "metadata": {},
   "source": [
    "#### Canonical space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c916a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_mask1 = np.hstack([np.where(mask[brain_mask > 0] == r)[0] for r in [215,216,217,218]])\n",
    "pca_canonical = PCA(n_components=12)\n",
    "data = np.mean(movie_data[:,roi_mask1][:,:,rest_tr], axis=0)\n",
    "data_hipp = pca_canonical.fit(data.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subspace analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f58e99e",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30856d9d",
   "metadata": {},
   "source": [
    "#### Novelty & Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7515638",
   "metadata": {},
   "outputs": [],
   "source": [
    "which_cognition = 'memory'\n",
    "\n",
    "np.random.seed(2023)\n",
    "\n",
    "repetition = 10\n",
    "beta_true = []\n",
    "beta_perm = []\n",
    "for data_pattern in patterns:\n",
    "    beta_tot_true = []\n",
    "    beta_tot_perm = []\n",
    "    for repeat in range(repetition + 1):\n",
    "        if repeat == 0:\n",
    "            if which_cognition == 'novelty':\n",
    "                conds = np.array([np.intersect1d(nove_cooccur_1, nove_valence_1), np.intersect1d(nove_cooccur_1, nove_valence_2), np.intersect1d(nove_cooccur_1, nove_valence_3),\n",
    "                                  np.intersect1d(nove_cooccur_2, nove_valence_1), np.intersect1d(nove_cooccur_2, nove_valence_2), np.intersect1d(nove_cooccur_2, nove_valence_3),\n",
    "                                  np.intersect1d(nove_cooccur_3, nove_valence_1), np.intersect1d(nove_cooccur_3, nove_valence_2), np.intersect1d(nove_cooccur_3, nove_valence_3)])\n",
    "            elif which_cognition == 'valence':\n",
    "                conds = np.array(np.array_split(np.argsort(valence), 6))\n",
    "            elif which_cognition == 'memory':\n",
    "                conds = np.array_split(np.argsort(-memorability), 9) # from low to high\n",
    "            \n",
    "            conds_regressor = []\n",
    "            for cd in conds:\n",
    "                cr = np.zeros(43)\n",
    "                cr[cd] = 1\n",
    "                conds_regressor.append(cr)\n",
    "\n",
    "            FIR_tot = []\n",
    "            for s in range(movie_data.shape[0]):\n",
    "                F = np.array([conds_regressor[cr] for cr in range(len(conds_regressor))])\n",
    "                beta = []\n",
    "                for t in range(window_length):\n",
    "                    beta.append(np.dot(np.dot(np.linalg.inv(np.dot(F, F.T)), F), data_pattern[s][:,:,t]))\n",
    "                FIR_tot.append(beta)\n",
    "            FIR_tot = np.array(FIR_tot)\n",
    "\n",
    "            for s in range(movie_data.shape[0]):\n",
    "                if which_cognition == 'novelty':\n",
    "                    F = np.array([[-1,-1,-1,0,0,0,1,1,1],\n",
    "                                  [-1,0,1,-1,0,1,-1,0,1],\n",
    "                                  [1,1,1,1,1,1,1,1,1]]) \n",
    "                elif which_cognition == 'valence':\n",
    "                    F = np.array([[-5,-3,-1,1,3,5],\n",
    "                                  [1,1,1,1,1,1]])  \n",
    "                elif which_cognition == 'memory':   \n",
    "                    F = np.array([[np.mean(memorability[ev]) - np.mean(memorability) for ev in conds],\n",
    "                                  [1,1,1,1,1,1,1,1,1]])             \n",
    "                beta = []\n",
    "                for t in range(window_length):\n",
    "                    beta.append(np.dot(np.dot(np.linalg.inv(np.dot(F, F.T)), F), FIR_tot[s][t]))\n",
    "                beta_tot_true.append(beta)    \n",
    "\n",
    "        else:\n",
    "            conds_regressor = []\n",
    "            for cd in conds:\n",
    "                cr = np.zeros(43)\n",
    "                cr[cd] = 1\n",
    "                conds_regressor.append(cr)\n",
    "\n",
    "            FIR_tot = []\n",
    "            for s in range(movie_data.shape[0]):\n",
    "                F = np.array([conds_regressor[cr] for cr in range(len(conds_regressor))])\n",
    "                beta = []\n",
    "                for t in range(window_length):\n",
    "                    beta.append(np.dot(np.dot(np.linalg.inv(np.dot(F, F.T)), F), data_pattern[s][:,:,t]))\n",
    "                FIR_tot.append(beta)\n",
    "            FIR_tot = np.array(FIR_tot)\n",
    "\n",
    "            betas = []\n",
    "            for s in range(movie_data.shape[0]):\n",
    "                if which_cognition == 'novelty':\n",
    "                    F = np.array([[-1,-1,-1,0,0,0,1,1,1],\n",
    "                                  [-1,0,1,-1,0,1,-1,0,1],\n",
    "                                  [1,1,1,1,1,1,1,1,1]]) \n",
    "                elif which_cognition == 'valence':\n",
    "                    F = np.array([[-5,-3,-1,1,3,5],\n",
    "                                  [1,1,1,1,1,1]])  \n",
    "                elif which_cognition == 'memory':\n",
    "                    F = np.array([[np.mean(memorability[ev]) - np.mean(memorability) for ev in conds],\n",
    "                                  [1,1,1,1,1,1,1,1,1]])                          \n",
    "                np.random.shuffle(F.T)\n",
    "                beta = []\n",
    "                for t in range(window_length):\n",
    "                    beta.append(np.dot(np.dot(np.linalg.inv(np.dot(F, F.T)), F), FIR_tot[s][t]))\n",
    "                betas.append(beta)\n",
    "            beta_tot_perm.append(betas)\n",
    "    beta_true.append(np.array(beta_tot_true))\n",
    "    beta_perm.append(np.array(beta_tot_perm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28564ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_true_novelty = beta_true\n",
    "beta_perm_novelty = beta_perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1eb98ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_true_memory = beta_true\n",
    "beta_perm_memory = beta_perm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "ba71d35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2023)\n",
    "\n",
    "repetition = 100\n",
    "beta_true_recall = []\n",
    "beta_perm_recall = []\n",
    "for data_pattern in patterns_recall:\n",
    "    beta_tot_true = []\n",
    "    beta_tot_perm = []\n",
    "    for repeat in range(repetition + 1):\n",
    "        if repeat == 0:\n",
    "            for s in range(movie_data.shape[0]):\n",
    "\n",
    "                score_sub = Memorability_score_total[s][event_idx[s]]\n",
    "                recall_task6 = np.where(score_sub >= np.percentile(score_sub, 500/6))[0]\n",
    "                recall_task5 = np.where((score_sub >= np.percentile(score_sub, 400/6)) & (score_sub < np.percentile(score_sub, 500/6)))[0]\n",
    "                recall_task4 = np.where((score_sub >= np.percentile(score_sub, 300/6)) & (score_sub < np.percentile(score_sub, 400/6)))[0]\n",
    "                recall_task3 = np.where((score_sub >= np.percentile(score_sub, 200/6)) & (score_sub < np.percentile(score_sub, 300/6)))[0]\n",
    "                recall_task2 = np.where((score_sub >= np.percentile(score_sub, 100/6)) & (score_sub < np.percentile(score_sub, 200/6)))[0]\n",
    "                recall_task1 = np.where(score_sub < np.percentile(score_sub, 100/6))[0]\n",
    "\n",
    "                conds = np.array([recall_task6, recall_task5, recall_task4, recall_task3, recall_task2, recall_task1])\n",
    "                \n",
    "                conds_regressor = []\n",
    "                for cd in conds:\n",
    "                    cr = np.zeros(len(score_sub))\n",
    "                    cr[cd] = 1\n",
    "                    conds_regressor.append(cr)\n",
    "                    \n",
    "                F = np.array([conds_regressor[cr] for cr in range(len(conds_regressor))])\n",
    "                FIR_tot = []\n",
    "                for t in range(window_length):\n",
    "                    FIR_tot.append(np.dot(np.dot(np.linalg.inv(np.dot(F, F.T)), F), data_pattern[s][:,:,t]))\n",
    "                FIR_tot = np.array(FIR_tot)\n",
    "\n",
    "                F = np.array([[np.mean(score_sub[ev]) - np.mean(score_sub) for ev in conds],\n",
    "                              [1,1,1,1,1,1]])                \n",
    "                beta = []\n",
    "                for t in range(window_length):\n",
    "                    beta.append(np.dot(np.dot(np.linalg.inv(np.dot(F, F.T)), F), FIR_tot[t]))\n",
    "                beta_tot_true.append(beta)    \n",
    "\n",
    "        else:\n",
    "            betas = []\n",
    "            for s in range(movie_data.shape[0]):\n",
    "                \n",
    "                score_sub = Memorability_score_total[s][event_idx[s]]\n",
    "                recall_task6 = np.where(score_sub >= np.percentile(score_sub, 500/6))[0]\n",
    "                recall_task5 = np.where((score_sub >= np.percentile(score_sub, 400/6)) & (score_sub < np.percentile(score_sub, 500/6)))[0]\n",
    "                recall_task4 = np.where((score_sub >= np.percentile(score_sub, 300/6)) & (score_sub < np.percentile(score_sub, 400/6)))[0]\n",
    "                recall_task3 = np.where((score_sub >= np.percentile(score_sub, 200/6)) & (score_sub < np.percentile(score_sub, 300/6)))[0]\n",
    "                recall_task2 = np.where((score_sub >= np.percentile(score_sub, 100/6)) & (score_sub < np.percentile(score_sub, 200/6)))[0]\n",
    "                recall_task1 = np.where(score_sub < np.percentile(score_sub, 100/6))[0]\n",
    "\n",
    "                conds = np.array([recall_task6, recall_task5, recall_task4, recall_task3, recall_task2, recall_task1])\n",
    "                \n",
    "                conds_regressor = []\n",
    "                for cd in conds:\n",
    "                    cr = np.zeros(len(score_sub))\n",
    "                    cr[cd] = 1\n",
    "                    conds_regressor.append(cr)\n",
    "\n",
    "                F = np.array([conds_regressor[cr] for cr in range(len(conds_regressor))])\n",
    "                FIR_tot = []\n",
    "                for t in range(window_length):\n",
    "                    FIR_tot.append(np.dot(np.dot(np.linalg.inv(np.dot(F, F.T)), F), data_pattern[s][:,:,t]))\n",
    "                FIR_tot = np.array(FIR_tot)\n",
    "                \n",
    "                F = np.array([[np.mean(score_sub[ev]) - np.mean(score_sub) for ev in conds],\n",
    "                              [1,1,1,1,1,1]])           \n",
    "                np.random.shuffle(F.T)\n",
    "                beta = []\n",
    "                for t in range(window_length):\n",
    "                    beta.append(np.dot(np.dot(np.linalg.inv(np.dot(F, F.T)), F), FIR_tot[t]))\n",
    "                betas.append(beta)\n",
    "            beta_tot_perm.append(betas)\n",
    "    beta_true_recall.append(np.array(beta_tot_true))\n",
    "    beta_perm_recall.append(np.array(beta_tot_perm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_true_recall_start = beta_true_recall\n",
    "beta_perm_recall_start = beta_perm_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_true_recall_end = beta_true_recall\n",
    "beta_perm_recall_end = beta_perm_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d7cc6a",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1696e26e",
   "metadata": {},
   "source": [
    "#### projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03964f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIR_tot_novelty_ev = np.load('/media/dasom/caee0336-77a9-438c-af2f-7cf5b88293e7/dasom/Neural_subspace/results/FIR_tot_novelty_ev.npy')\n",
    "FIR_tot_memory_ev = np.load('/media/dasom/caee0336-77a9-438c-af2f-7cf5b88293e7/dasom/Neural_subspace/results/FIR_tot_memory_ev.npy')\n",
    "FIR_tot_recall_ev = np.load('/media/dasom/caee0336-77a9-438c-af2f-7cf5b88293e7/dasom/Neural_subspace/results/FIR_tot_recall_start_ev.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d90892c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# memorability\n",
    "F = []\n",
    "for ev in np.array_split(np.argsort(-memorability), 9):\n",
    "    a = np.zeros(43)\n",
    "    a[ev] = 1 \n",
    "    F.append(a)\n",
    "F = np.array(F)\n",
    "\n",
    "FIR_tot_memory_ev = []\n",
    "for data_pattern in patterns:\n",
    "    FIR_ev = []\n",
    "    for s in range(movie_data.shape[0]):\n",
    "        beta = []\n",
    "        for t in range(window_length):\n",
    "            beta.append(np.dot(np.dot(np.linalg.inv(np.dot(F, F.T)), F), data_pattern[s][:,:,t]))\n",
    "        FIR_ev.append(beta)\n",
    "    FIR_tot_memory_ev.append(np.array(FIR_ev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b5f5573",
   "metadata": {},
   "outputs": [],
   "source": [
    "fMRI_data = FIR_tot_memory_ev\n",
    "pc_num = [window_length-1]*len(patterns)\n",
    "\n",
    "pc1_evs = []\n",
    "pc2_evs = []\n",
    "p_c1_trues = []\n",
    "p_c2_trues = []\n",
    "p_c1_perms = []\n",
    "p_c2_perms = []\n",
    "\n",
    "for r in range(len(patterns)):\n",
    "\n",
    "    beta_pcas = beta_true_memory[r]\n",
    "\n",
    "    pca_c1 = PCA(n_components=pc_num[r])\n",
    "    data = np.mean(beta_pcas, axis=0)[:,0].T\n",
    "    data_c1 = pca_c1.fit(data.T)\n",
    "    pcs_c1 = data_c1.components_\n",
    "    pc1_evs.append(np.cumsum(pca_c1.explained_variance_ratio_))\n",
    "\n",
    "    pca_c2 = PCA(n_components=pc_num[r])\n",
    "    data = np.mean(beta_pcas, axis=0)[:,1].T\n",
    "    data_c2 = pca_c2.fit(data.T)\n",
    "    pcs_c2 = data_c2.components_\n",
    "    pc2_evs.append(np.cumsum(pca_c2.explained_variance_ratio_))\n",
    "\n",
    "    p_c1_true = []\n",
    "    p_c2_true = []\n",
    "    for c in range(fMRI_data[0][0].shape[1]):\n",
    "        p_c1_true.append(np.dot(pcs_c1, np.mean(fMRI_data[r], axis=0)[:,c].T))\n",
    "        p_c2_true.append(np.dot(pcs_c2, np.mean(fMRI_data[r], axis=0)[:,c].T))\n",
    "\n",
    "    p_c1s = []\n",
    "    p_c2s = []\n",
    "    for repeat in range(repetition):\n",
    "        \n",
    "        beta_pcas = beta_perm_memory[r][repeat]\n",
    "\n",
    "        pca_c1 = PCA(n_components=pc_num[r])\n",
    "        data = np.mean(beta_pcas, axis=0)[:,0].T\n",
    "        data_c1 = pca_c1.fit(data.T)\n",
    "        pcs_c1 = data_c1.components_\n",
    "\n",
    "        pca_c2 = PCA(n_components=pc_num[r])\n",
    "        data = np.mean(beta_pcas, axis=0)[:,1].T\n",
    "        data_c2 = pca_c2.fit(data.T)\n",
    "        pcs_c2 = data_c2.components_\n",
    "\n",
    "        c1s = []\n",
    "        c2s = []\n",
    "        for c in range(fMRI_data[0][0].shape[1]):\n",
    "            c1s.append(np.dot(pcs_c1, np.mean(fMRI_data[r], axis=0)[:,c].T))\n",
    "            c2s.append(np.dot(pcs_c2, np.mean(fMRI_data[r], axis=0)[:,c].T))\n",
    "        p_c1s.append(c1s)\n",
    "        p_c2s.append(c2s)\n",
    "\n",
    "    p_c1_trues.append(np.array(p_c1_true))\n",
    "    p_c2_trues.append(np.array(p_c2_true))\n",
    "    p_c1_perms.append(np.array(p_c1s))\n",
    "    p_c2_perms.append(np.array(p_c2s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# novelty_co_space_novelty_true = p_c1_trues\n",
    "# novelty_val_space_novelty_true = p_c2_trues\n",
    "# novelty_co_space_novelty_perm = p_c1_perms\n",
    "# novelty_val_space_novelty_perm = p_c2_perms\n",
    "\n",
    "# novelty_co_space_memory_true = p_c1_trues\n",
    "# novelty_val_space_memory_true = p_c2_trues\n",
    "# novelty_co_space_memory_perm = p_c1_perms\n",
    "# novelty_val_space_memory_perm = p_c2_perms\n",
    "\n",
    "memory_space_memory_true = p_c1_trues\n",
    "memory_space_memory_perm = p_c1_perms\n",
    "\n",
    "# memory_space_novelty_true = p_c1_trues\n",
    "# memory_space_novelty_perm = p_c1_perms\n",
    "\n",
    "# recall_start_space_recall_true = p_c1_trues\n",
    "# recall_start_space_recall_perm = p_c1_perms\n",
    "\n",
    "# recall_end_space_recall_true = p_c1_trues\n",
    "# recall_end_space_recall_perm = p_c1_perms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
